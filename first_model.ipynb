{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "k4i7UDH919kL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RYv8pJ0nA7-v"
   },
   "outputs": [],
   "source": [
    "pd_test = pd.read_csv(\"test_mul.csv\",dtype=\"str\",names=[\"a\",\"arxiv_id\",\"create_date\",\"update_date\",\"cats\",\"subcats\",\"title\",\"abstract\"]).iloc[1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HglJaUiUi708"
   },
   "outputs": [],
   "source": [
    "pd_train = pd.read_csv(\"train_mul.csv\",dtype=\"str\",names=[\"arxiv_id\",\"create_date\",\"update_date\",\"cats\",\"subcats\",\"title\",\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "UNzJd7A2FPeM",
    "outputId": "35255d1e-4978-4cd3-bb9d-3ee6029545ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91760, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VCgx4jXHj-6r"
   },
   "source": [
    "Clean up abstract using noun only phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "KTpdT-x1lyTp",
    "outputId": "0302e0e3-6a26-40d0-9a92-4cd9d34072af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Volumes/HD-500GB/Users/nikolausn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Volumes/HD-500GB/Users/nikolausn/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Volumes/HD-500GB/Users/nikolausn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gRTj9pzItAIP"
   },
   "outputs": [],
   "source": [
    "def noun_only_sentence(x_string):\n",
    "    string_list = x_string.lower().split(\".\")\n",
    "    noun_sentence = []\n",
    "    for my_str in string_list:\n",
    "        #print(my_str)\n",
    "        tokens = word_tokenize(my_str)\n",
    "        #bigrams = ngrams(token,2)\n",
    "        # remove all tokens that are not alphabetic\n",
    "        is_noun = lambda pos: pos[:2] == 'NN'\n",
    "        # do the nlp stuff\n",
    "        nouns = [word for (word, pos) in nltk.pos_tag(tokens) if is_noun(pos)] \n",
    "        noun_sentence.append(nouns)\n",
    "    return noun_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XR0Ue2lKldH5"
   },
   "outputs": [],
   "source": [
    "#abstract_noun = pd_train.abstract.apply(lambda x: noun_only_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9mFnz_bb8Vyb"
   },
   "outputs": [],
   "source": [
    "#abstract_noun_test = pd_test.abstract.apply(lambda x: noun_only_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q49nh0fkmAPI"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#with open(\"/gdrive/My Drive/Dataset/arxiv/abstract_noun.pickle\",\"wb\") as file:\n",
    "#  pickle.dump((abstract_noun,abstract_noun_test),file)\n",
    "with open(\"abstract_noun.pickle\",\"rb\") as file:\n",
    "  (abstract_noun,abstract_noun_test) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gZt8ozMmqnYZ"
   },
   "outputs": [],
   "source": [
    "# clean abstract noun so it will contain only alphabetic char\n",
    "\n",
    "# use english stop_words\n",
    "stop_words =  list(stopwords.words('english'))\n",
    "\n",
    "def alphabetic_only_l(x_string):\n",
    "  list_sent = []    \n",
    "  for tokens in x_string:\n",
    "    # remove all tokens that are not alphabetic\n",
    "    words = [word for word in tokens if word.isalpha() and word not in stop_words and len(word)>3]\n",
    "    list_sent.append(words)    \n",
    "  return list_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZzR6AvzFrUMY"
   },
   "outputs": [],
   "source": [
    "#abs_noun_clean = abstract_noun.apply(lambda x:alphabetic_only_l(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AaYWBsJl9o4c"
   },
   "outputs": [],
   "source": [
    "#abs_noun_clean_test = abstract_noun_test.apply(lambda x:alphabetic_only_l(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWpiT7DtrXP5"
   },
   "outputs": [],
   "source": [
    "#with open(\"/gdrive/My Drive/Dataset/arxiv/abstract_noun_clean.pickle\",\"wb\") as file:\n",
    "#  pickle.dump((abs_noun_clean,abs_noun_clean_test),file)\n",
    "with open(\"abstract_noun_clean.pickle\",\"rb\") as file:\n",
    "  (abs_noun_clean,abs_noun_clean_test) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ejix081jsZFS"
   },
   "outputs": [],
   "source": [
    "# features/words chooser using tfidf\n",
    "def sent_convert(x_string):\n",
    "  list_sent = []\n",
    "  for sent in x_string:\n",
    "    # remove all tokens that are not alphabetic    \n",
    "    list_sent.append(\" \".join(sent))    \n",
    "  return \". \".join(list_sent)\n",
    "\n",
    "abs_noun_sent = abs_noun_clean.apply(lambda x:sent_convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rLxvhHs09woQ"
   },
   "outputs": [],
   "source": [
    "abs_noun_sent_test = abs_noun_clean_test.apply(lambda x:sent_convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agq99pErsuta"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/HD-500GB/Users/nikolausn/Applications/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "tf = tf_vectorizer.fit_transform(abs_noun_sent.values)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf = tfidf_vectorizer.fit_transform(abs_noun_sent.values)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KUvRysAPtDwD",
    "outputId": "efac7c75-d0b0-49ee-ced2-f7f58254ec1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27752"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-N9zEQq2t-7Z"
   },
   "outputs": [],
   "source": [
    "tfidf_sum = tfidf.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bXe6ne19t6r3",
    "outputId": "ba14cf6b-4ddf-45c6-8ea1-070974040d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27752)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yyYCPvDFuhVU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# sort the tfidf_desc\n",
    "index_sort = np.argsort(tfidf_sum)[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NN5WCoIvv8Lv",
    "outputId": "467d14f5-1cad-4709-80bc-2e6693f5d43c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[15950,  5928, 21405, ...,   629, 13003,  3128]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YeZzWBgLwUxy"
   },
   "outputs": [],
   "source": [
    "pot_feat = [tfidf_feature_names[x] for x in index_sort.tolist()[0][:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17034
    },
    "colab_type": "code",
    "id": "OXgU9Lq2wjY7",
    "outputId": "0d245093-26fc-4097-ea58-f8117add44b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model',\n",
       " 'data',\n",
       " 'results',\n",
       " 'theory',\n",
       " 'energy',\n",
       " 'field',\n",
       " 'models',\n",
       " 'system',\n",
       " 'method',\n",
       " 'quantum',\n",
       " 'time',\n",
       " 'states',\n",
       " 'state',\n",
       " 'mass',\n",
       " 'systems',\n",
       " 'paper',\n",
       " 'order',\n",
       " 'function',\n",
       " 'phase',\n",
       " 'equation',\n",
       " 'approach',\n",
       " 'problem',\n",
       " 'analysis',\n",
       " 'number',\n",
       " 'space',\n",
       " 'case',\n",
       " 'structure',\n",
       " 'properties',\n",
       " 'equations',\n",
       " 'matter',\n",
       " 'solutions',\n",
       " 'dynamics',\n",
       " 'functions',\n",
       " 'distribution',\n",
       " 'density',\n",
       " 'parameters',\n",
       " 'collisions',\n",
       " 'lattice',\n",
       " 'symmetry',\n",
       " 'effects',\n",
       " 'methods',\n",
       " 'terms',\n",
       " 'information',\n",
       " 'network',\n",
       " 'limit',\n",
       " 'production',\n",
       " 'transition',\n",
       " 'framework',\n",
       " 'work',\n",
       " 'measurements',\n",
       " 'temperature',\n",
       " 'process',\n",
       " 'solution',\n",
       " 'algorithm',\n",
       " 'conditions',\n",
       " 'parameter',\n",
       " 'fields',\n",
       " 'interaction',\n",
       " 'interactions',\n",
       " 'networks',\n",
       " 'result',\n",
       " 'form',\n",
       " 'study',\n",
       " 'effect',\n",
       " 'physics',\n",
       " 'decay',\n",
       " 'gauge',\n",
       " 'range',\n",
       " 'experiments',\n",
       " 'simulations',\n",
       " 'potential',\n",
       " 'values',\n",
       " 'particles',\n",
       " 'particle',\n",
       " 'gravity',\n",
       " 'quark',\n",
       " 'value',\n",
       " 'momentum',\n",
       " 'point',\n",
       " 'rate',\n",
       " 'theories',\n",
       " 'spectrum',\n",
       " 'evolution',\n",
       " 'class',\n",
       " 'group',\n",
       " 'matrix',\n",
       " 'calculations',\n",
       " 'spin',\n",
       " 'coupling',\n",
       " 'cross',\n",
       " 'power',\n",
       " 'behavior',\n",
       " 'performance',\n",
       " 'distributions',\n",
       " 'level',\n",
       " 'region',\n",
       " 'dependence',\n",
       " 'operators',\n",
       " 'approximation',\n",
       " 'flow']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ax2bDGKjy2Nd",
    "outputId": "4155ad40-1e16-4cd8-b869-cb0a44b9a896"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>create_date</th>\n",
       "      <th>update_date</th>\n",
       "      <th>cats</th>\n",
       "      <th>subcats</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1508.05418</td>\n",
       "      <td>2015-08-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math</td>\n",
       "      <td>math.AT|math.AG|math.CO|math.RA</td>\n",
       "      <td>The Cohomology of Quaternionic Hyperplane Comp...</td>\n",
       "      <td>Over the complex numbers, the complement of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1411.6304</td>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math-ph|math</td>\n",
       "      <td>math-ph|math.MP</td>\n",
       "      <td>Dephasing of Kuramoto oscillators in kinetic r...</td>\n",
       "      <td>We study the kinetic Kuramoto model for couple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1402.0313</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs|math</td>\n",
       "      <td>cs.IT|math.IT</td>\n",
       "      <td>Rate-Distortion Properties of Single-Layer Qua...</td>\n",
       "      <td>The Quantize &amp; Forward (QF) scheme for two-way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1611.07471</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>math</td>\n",
       "      <td>math.AG</td>\n",
       "      <td>Distinguished models of intermediate Jacobians</td>\n",
       "      <td>We show that the image of the Abel-Jacobi map ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1806.00355</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math</td>\n",
       "      <td>math.HO|math.NT</td>\n",
       "      <td>Mahler's work on Diophantine equations and sub...</td>\n",
       "      <td>We discuss Mahler's work on Diophantine approx...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arxiv_id create_date update_date          cats  \\\n",
       "0  1508.05418  2015-08-21         NaN          math   \n",
       "1   1411.6304  2014-11-23         NaN  math-ph|math   \n",
       "2   1402.0313  2014-02-03         NaN       cs|math   \n",
       "3  1611.07471  2016-11-22  2018-04-04          math   \n",
       "4  1806.00355  2018-05-31         NaN          math   \n",
       "\n",
       "                           subcats  \\\n",
       "0  math.AT|math.AG|math.CO|math.RA   \n",
       "1                  math-ph|math.MP   \n",
       "2                    cs.IT|math.IT   \n",
       "3                          math.AG   \n",
       "4                  math.HO|math.NT   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Cohomology of Quaternionic Hyperplane Comp...   \n",
       "1  Dephasing of Kuramoto oscillators in kinetic r...   \n",
       "2  Rate-Distortion Properties of Single-Layer Qua...   \n",
       "3     Distinguished models of intermediate Jacobians   \n",
       "4  Mahler's work on Diophantine equations and sub...   \n",
       "\n",
       "                                            abstract  \n",
       "0  Over the complex numbers, the complement of a ...  \n",
       "1  We study the kinetic Kuramoto model for couple...  \n",
       "2  The Quantize & Forward (QF) scheme for two-way...  \n",
       "3  We show that the image of the Abel-Jacobi map ...  \n",
       "4  We discuss Mahler's work on Diophantine approx...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-qJJsNVz8Ik"
   },
   "source": [
    "extracting the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Kk--kLDKy_1I"
   },
   "outputs": [],
   "source": [
    "y_train_label = pd_train.cats.apply(lambda x: x.split(\"|\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "1htVdnaS0Fke",
    "outputId": "7a0a9515-7af9-43a1-f2a2-4001618cfb78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['math', 'math-ph', 'cs', 'quant-ph', 'hep-th', 'stat', 'cond-mat',\n",
       "       'q-fin', 'nlin', 'physics', 'gr-qc', 'q-bio', 'eess', 'astro-ph',\n",
       "       'nucl-th', 'econ', 'hep-ph', 'hep-lat', 'nucl-ex', 'hep-ex'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cferJsXV0OBT"
   },
   "outputs": [],
   "source": [
    "y_train_class = y_train_label.apply(lambda x:list(y_train_label.unique()).index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T7qlwbWR0XYj"
   },
   "outputs": [],
   "source": [
    "y_test_class = pd_test.cats.apply(lambda x: x.split(\"|\")[0]).apply(lambda x:list(y_train_label.unique()).index(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AJAO80oAav1"
   },
   "source": [
    "**Logistic Regression Model over TF-IDF vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SGXBk9iS5szg"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "X_train = tfidf[:,index_sort.tolist()[0][:num_features]]\n",
    "y_train = y_train_class.values\n",
    "lr_cv = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rhqnveqg6PSs"
   },
   "outputs": [],
   "source": [
    "X_test = tfidf_vectorizer.transform(abs_noun_sent_test.values)[:,index_sort.tolist()[0][:num_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pcsMnyB0-qXL",
    "outputId": "210ea8d0-52bf-4d66-a015-2b628bfb164e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18942, 10000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OHD-7d_V-ssN"
   },
   "outputs": [],
   "source": [
    "y_test_pred = lr_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BO1lWF31-5tG"
   },
   "source": [
    "Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "33bP7Tu3-2CN",
    "outputId": "ce98e967-602e-4a34-a474-07b773697c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6944884383908774\n",
      "kappa: 0.6734105587931851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.74      0.68      1593\n",
      "          1       0.48      0.34      0.40       644\n",
      "          2       0.63      0.75      0.69      1547\n",
      "          3       0.75      0.69      0.72      1009\n",
      "          4       0.67      0.71      0.69      1118\n",
      "          5       0.59      0.58      0.59       667\n",
      "          6       0.71      0.75      0.73      1389\n",
      "          7       0.85      0.86      0.86       998\n",
      "          8       0.62      0.56      0.59       550\n",
      "          9       0.59      0.61      0.60      1539\n",
      "         10       0.71      0.67      0.69       881\n",
      "         11       0.68      0.69      0.68       778\n",
      "         12       0.55      0.24      0.33       363\n",
      "         13       0.85      0.81      0.83      1321\n",
      "         14       0.72      0.68      0.70       926\n",
      "         15       0.75      0.05      0.09        66\n",
      "         16       0.74      0.80      0.77      1856\n",
      "         17       0.84      0.76      0.80       785\n",
      "         18       0.69      0.58      0.63       466\n",
      "         19       0.78      0.65      0.71       446\n",
      "\n",
      "avg / total       0.69      0.69      0.69     18942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,cohen_kappa_score\n",
    "acc = accuracy_score(y_test_class,y_test_pred)\n",
    "kap = cohen_kappa_score(y_test_class,y_test_pred)\n",
    "print(\"accuracy:\",acc)\n",
    "print(\"kappa:\",kap)\n",
    "print(classification_report(y_test_class,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUCDlFYCAWql"
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHFOOEzTAVxp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/HD-500GB/Users/nikolausn/Applications/anaconda/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=500,random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "EozhL4eL-3BL",
    "outputId": "aa2f7298-9f63-4c48-f1f9-9e5dc95e659f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6898426776475557\n",
      "kappa: 0.6676397886425085\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.77      0.63      1593\n",
      "          1       0.75      0.25      0.38       644\n",
      "          2       0.55      0.82      0.66      1547\n",
      "          3       0.73      0.73      0.73      1009\n",
      "          4       0.66      0.68      0.67      1118\n",
      "          5       0.63      0.45      0.53       667\n",
      "          6       0.64      0.73      0.68      1389\n",
      "          7       0.84      0.89      0.86       998\n",
      "          8       0.74      0.51      0.61       550\n",
      "          9       0.62      0.48      0.54      1539\n",
      "         10       0.70      0.69      0.70       881\n",
      "         11       0.70      0.61      0.65       778\n",
      "         12       0.95      0.12      0.21       363\n",
      "         13       0.84      0.80      0.82      1321\n",
      "         14       0.78      0.75      0.77       926\n",
      "         15       1.00      0.39      0.57        66\n",
      "         16       0.73      0.86      0.79      1856\n",
      "         17       0.88      0.81      0.85       785\n",
      "         18       0.89      0.55      0.68       466\n",
      "         19       0.91      0.68      0.78       446\n",
      "\n",
      "avg / total       0.71      0.69      0.68     18942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,cohen_kappa_score\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "acc = accuracy_score(y_test_class,y_test_pred)\n",
    "kap = cohen_kappa_score(y_test_class,y_test_pred)\n",
    "print(\"accuracy:\",acc)\n",
    "print(\"kappa:\",kap)\n",
    "print(classification_report(y_test_class,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBeEJyKlCWTV"
   },
   "source": [
    "**SVM classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Uii6oSL_CQj0",
    "outputId": "a32f0883-79fb-4089-f499-cf136df72768"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_svm_model = svm.LinearSVC()\n",
    "lin_svm_model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "fg5hG-lKDiIB",
    "outputId": "f55e48f3-df6d-49d8-947d-e2c6c6ea9a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7034104107274839\n",
      "kappa: 0.6832999746660589\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.71      0.68      1593\n",
      "          1       0.50      0.35      0.41       644\n",
      "          2       0.65      0.73      0.69      1547\n",
      "          3       0.74      0.73      0.73      1009\n",
      "          4       0.68      0.73      0.70      1118\n",
      "          5       0.57      0.56      0.57       667\n",
      "          6       0.72      0.74      0.73      1389\n",
      "          7       0.85      0.89      0.87       998\n",
      "          8       0.60      0.60      0.60       550\n",
      "          9       0.61      0.57      0.59      1539\n",
      "         10       0.71      0.71      0.71       881\n",
      "         11       0.68      0.73      0.70       778\n",
      "         12       0.54      0.32      0.40       363\n",
      "         13       0.85      0.83      0.84      1321\n",
      "         14       0.73      0.69      0.71       926\n",
      "         15       0.56      0.27      0.37        66\n",
      "         16       0.75      0.81      0.78      1856\n",
      "         17       0.83      0.82      0.83       785\n",
      "         18       0.70      0.62      0.66       466\n",
      "         19       0.78      0.67      0.72       446\n",
      "\n",
      "avg / total       0.70      0.70      0.70     18942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,cohen_kappa_score\n",
    "y_test_pred = lin_svm_model.predict(X_test)\n",
    "acc = accuracy_score(y_test_class,y_test_pred)\n",
    "kap = cohen_kappa_score(y_test_class,y_test_pred)\n",
    "print(\"accuracy:\",acc)\n",
    "print(\"kappa:\",kap)\n",
    "print(classification_report(y_test_class,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pLDWQL9JGyfG"
   },
   "outputs": [],
   "source": [
    "with open(\"trained_first_model.pickle\",\"wb\") as file:\n",
    "  pickle.dump((lr_cv,rf_model,lin_svm_model),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91760, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91760,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "first_model",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
