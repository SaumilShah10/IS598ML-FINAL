{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "def is_noun(pos):\n",
    "    if pos in noun_tags:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(text):\n",
    "    nouns = []\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence)\n",
    "        sentence_nouns = [word.lower() for (word, pos) in pos_tag(tokens) if is_noun(pos)] \n",
    "        nouns += sentence_nouns\n",
    "    return ' '.join(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_level_categories(categories):\n",
    "    specific_categories = categories.split()\n",
    "    top_level_categories = set([category.split('.')[0] for category in specific_categories])\n",
    "    \n",
    "    return top_level_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113436\n",
      "123781\n",
      "113436\n",
      "123781\n"
     ]
    }
   ],
   "source": [
    "# Training set: 2016\n",
    "# Test set: 2017\n",
    "\n",
    "categories = set()\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "with open(os.path.join('data-by-year', '2016.json'), 'r') as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)['arXiv']\n",
    "        year = datetime.strptime(row['created'],\"%Y-%m-%d\").year\n",
    "        \n",
    "        row_categories = get_top_level_categories(row['categories'])\n",
    "        categories = categories.union(row_categories)\n",
    "\n",
    "        train_X.append(extract_nouns(row['title'] + '\\n ' + row['abstract']))\n",
    "        train_Y.append(row_categories)\n",
    "\n",
    "test_X = []\n",
    "test_Y = []    \n",
    "with open(os.path.join('data-by-year', '2017.json'), 'r') as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)['arXiv']\n",
    "        year = datetime.strptime(row['created'],\"%Y-%m-%d\").year\n",
    "        \n",
    "        row_categories = get_top_level_categories(row['categories'])\n",
    "        categories = categories.union(row_categories)\n",
    "\n",
    "        test_X.append(extract_nouns(row['title'] + '\\n ' + row['abstract']))\n",
    "        test_Y.append(row_categories)\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(train_Y))\n",
    "print(len(test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(list(categories))\n",
    "bin_train_Y = mlb.fit_transform(train_Y)\n",
    "bin_test_Y = mlb.fit_transform(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing gr-qc\n",
      "Instances: 4589\n",
      "Test accuracy is 0.9756263077532092\n",
      "Precision is 0.7771509167842031\n",
      "Recall is 0.48027892787099585\n",
      "... Processing stat\n",
      "Instances: 7538\n",
      "Test accuracy is 0.9529006875045443\n",
      "Precision is 0.6800927878532265\n",
      "Recall is 0.4278323162642611\n",
      "... Processing math\n",
      "Instances: 38456\n",
      "Test accuracy is 0.9004370622308755\n",
      "Precision is 0.8508404489554804\n",
      "Recall is 0.8239806532140628\n",
      "... Processing math-ph\n",
      "Instances: 3765\n",
      "Test accuracy is 0.9695106680346741\n",
      "Precision is 0.48632218844984804\n",
      "Recall is 0.04249667994687915\n",
      "... Processing q-fin\n",
      "Instances: 895\n",
      "Test accuracy is 0.9931815060469701\n",
      "Precision is 0.7802197802197802\n",
      "Recall is 0.07932960893854749\n",
      "... Processing nlin\n",
      "Instances: 1834\n",
      "Test accuracy is 0.9854985821733545\n",
      "Precision is 0.819672131147541\n",
      "Recall is 0.027262813522355506\n",
      "... Processing eess\n",
      "Instances: 698\n",
      "Test accuracy is 0.9943610085554325\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing hep-lat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ischool-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 1044\n",
      "Test accuracy is 0.9927856456160477\n",
      "Precision is 0.8132780082987552\n",
      "Recall is 0.18773946360153257\n",
      "... Processing econ\n",
      "Instances: 109\n",
      "Test accuracy is 0.9991194125108054\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing nucl-ex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ischool-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 1216\n",
      "Test accuracy is 0.9894167925610554\n",
      "Precision is 0.44835164835164837\n",
      "Recall is 0.3355263157894737\n",
      "... Processing astro-ph\n",
      "Instances: 15127\n",
      "Test accuracy is 0.9712152915229316\n",
      "Precision is 0.9388947927736451\n",
      "Recall is 0.8176770013882462\n",
      "... Processing cond-mat\n",
      "Instances: 17576\n",
      "Test accuracy is 0.940653250498865\n",
      "Precision is 0.8198874296435272\n",
      "Recall is 0.7459035047792444\n",
      "... Processing hep-ph\n",
      "Instances: 6539\n",
      "Test accuracy is 0.9701973647005598\n",
      "Precision is 0.7372627372627373\n",
      "Recall is 0.6771677626548402\n",
      "... Processing quant-ph\n",
      "Instances: 7020\n",
      "Test accuracy is 0.9605755325938553\n",
      "Precision is 0.8465025906735751\n",
      "Recall is 0.37236467236467236\n",
      "... Processing cs\n",
      "Instances: 30686\n",
      "Test accuracy is 0.9233000218127176\n",
      "Precision is 0.8336902437488191\n",
      "Recall is 0.8627061200547481\n",
      "... Processing q-bio\n",
      "Instances: 2482\n",
      "Test accuracy is 0.9819843110008806\n",
      "Precision is 0.7635983263598326\n",
      "Recall is 0.14705882352941177\n",
      "... Processing physics\n",
      "Instances: 14548\n",
      "Test accuracy is 0.9031515337572003\n",
      "Precision is 0.704211869814933\n",
      "Recall is 0.30340940335441297\n",
      "... Processing hep-th\n",
      "Instances: 6209\n",
      "Test accuracy is 0.9655359061568415\n",
      "Precision is 0.736893440624238\n",
      "Recall is 0.48671283620550815\n",
      "... Processing nucl-th\n",
      "Instances: 2301\n",
      "Test accuracy is 0.9812895355506903\n",
      "Precision is 0.49504950495049505\n",
      "Recall is 0.3259452411994785\n",
      "... Processing hep-ex\n",
      "Instances: 2514\n",
      "Test accuracy is 0.9800454027677915\n",
      "Precision is 0.5070558050032072\n",
      "Recall is 0.6288782816229117\n"
     ]
    }
   ],
   "source": [
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(max_features = 2000)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "nb_predictions = []\n",
    "for i in range(len(categories)):\n",
    "    print('... Processing {}'.format(mlb.classes_[i]))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(train_X, bin_train_Y[:,i])\n",
    "    \n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(test_X)\n",
    "    nb_predictions.append(prediction)\n",
    "    \n",
    "    print('Instances: {}'.format(np.sum(bin_test_Y[:,i])))\n",
    "    print('Test accuracy is {}'.format(accuracy_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Precision is {}'.format(precision_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Recall is {}'.format(recall_score(bin_test_Y[:,i], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing gr-qc\n",
      "Instances: 4589\n",
      "Test accuracy is 0.9751738958321552\n",
      "Precision is 0.7809488510007413\n",
      "Recall is 0.4591414251470909\n",
      "... Processing stat\n",
      "Instances: 7538\n",
      "Test accuracy is 0.9545164443654519\n",
      "Precision is 0.7200184501845018\n",
      "Recall is 0.4141682143804723\n",
      "... Processing math\n",
      "Instances: 38456\n",
      "Test accuracy is 0.9083138769277999\n",
      "Precision is 0.8871433060070267\n",
      "Recall is 0.8076242978988974\n",
      "... Processing math-ph\n",
      "Instances: 3765\n",
      "Test accuracy is 0.9702539161906917\n",
      "Precision is 0.562406015037594\n",
      "Recall is 0.09933598937583002\n",
      "... Processing q-fin\n",
      "Instances: 895\n",
      "Test accuracy is 0.9943933236926508\n",
      "Precision is 0.8316831683168316\n",
      "Recall is 0.28156424581005585\n",
      "... Processing nlin\n",
      "Instances: 1834\n",
      "Test accuracy is 0.9861772000549357\n",
      "Precision is 0.8682634730538922\n",
      "Recall is 0.07906215921483097\n",
      "... Processing eess\n",
      "Instances: 698\n",
      "Test accuracy is 0.9943610085554325\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing hep-lat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ischool-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 1044\n",
      "Test accuracy is 0.9925271245183025\n",
      "Precision is 0.7989949748743719\n",
      "Recall is 0.15229885057471265\n",
      "... Processing econ\n",
      "Instances: 109\n",
      "Test accuracy is 0.9991194125108054\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing nucl-ex\n",
      "Instances: 1216\n",
      "Test accuracy is 0.9911618099708356\n",
      "Precision is 0.5938461538461538\n",
      "Recall is 0.31743421052631576\n",
      "... Processing astro-ph\n",
      "Instances: 15127\n",
      "Test accuracy is 0.9728229695995346\n",
      "Precision is 0.9562485454968582\n",
      "Recall is 0.8149005090236002\n",
      "... Processing cond-mat\n",
      "Instances: 17576\n",
      "Test accuracy is 0.9455570725717194\n",
      "Precision is 0.8493327316098253\n",
      "Recall is 0.7495448338643604\n",
      "... Processing hep-ph\n",
      "Instances: 6539\n",
      "Test accuracy is 0.9712556854444543\n",
      "Precision is 0.7593527057595267\n",
      "Recall is 0.6673803333843096\n",
      "... Processing quant-ph\n",
      "Instances: 7020\n",
      "Test accuracy is 0.9619489259256268\n",
      "Precision is 0.8704297626683771\n",
      "Recall is 0.3866096866096866\n",
      "... Processing cs\n",
      "Instances: 30686\n",
      "Test accuracy is 0.9277514319645179\n",
      "Precision is 0.862879268333389\n",
      "Recall is 0.8424362901648961\n",
      "... Processing q-bio\n",
      "Instances: 2482\n",
      "Test accuracy is 0.9839312980182742\n",
      "Precision is 0.7467467467467468\n",
      "Recall is 0.3005640612409347\n",
      "... Processing physics\n",
      "Instances: 14548\n",
      "Test accuracy is 0.91215937825676\n",
      "Precision is 0.7303497555471982\n",
      "Recall is 0.4004674182018147\n",
      "... Processing hep-th\n",
      "Instances: 6209\n",
      "Test accuracy is 0.9680645656441619\n",
      "Precision is 0.7745861733203505\n",
      "Recall is 0.5124818811402803\n",
      "... Processing nucl-th\n",
      "Instances: 2301\n",
      "Test accuracy is 0.9826952440196799\n",
      "Precision is 0.562255285826155\n",
      "Recall is 0.31203824424163407\n",
      "... Processing hep-ex\n",
      "Instances: 2514\n",
      "Test accuracy is 0.9821539654712759\n",
      "Precision is 0.553753965456468\n",
      "Recall is 0.6249005568814638\n"
     ]
    }
   ],
   "source": [
    "nb_predictions = []\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    print('... Processing {}'.format(mlb.classes_[i]))\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "    tfidf_matrix =  vectorizer.fit_transform(np.array(train_X)[bin_train_Y[:,i] == 1])\n",
    "    \n",
    "    clf = MultinomialNB(fit_prior=True, class_prior=None)\n",
    "    clf.fit(vectorizer.transform(train_X), bin_train_Y[:,i])\n",
    "    \n",
    "    # compute the testing accuracy\n",
    "    prediction = clf.predict(vectorizer.transform(test_X))\n",
    "    nb_predictions.append(prediction)\n",
    "    \n",
    "    print('Instances: {}'.format(np.sum(bin_test_Y[:,i])))\n",
    "    print('Test accuracy is {}'.format(accuracy_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Precision is {}'.format(precision_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Recall is {}'.format(recall_score(bin_test_Y[:,i], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing cs\n",
      "Instances: 30686\n",
      "Test accuracy is 0.9346103198390706\n",
      "Precision is 0.8839303922235062\n",
      "Recall is 0.8475200417128332\n",
      "... Processing eess\n",
      "Instances: 698\n",
      "Test accuracy is 0.9943610085554325\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing physics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 14548\n",
      "Test accuracy is 0.9132015414320453\n",
      "Precision is 0.7213171980451478\n",
      "Recall is 0.4261066813307671\n",
      "... Processing q-bio\n",
      "Instances: 2482\n",
      "Test accuracy is 0.9843756311550238\n",
      "Precision is 0.6900138696255201\n",
      "Recall is 0.4008863819500403\n",
      "... Processing q-fin\n",
      "Instances: 895\n",
      "Test accuracy is 0.9944014024769553\n",
      "Precision is 0.7295454545454545\n",
      "Recall is 0.358659217877095\n",
      "... Processing hep-ex\n",
      "Instances: 2514\n",
      "Test accuracy is 0.9845856795469418\n",
      "Precision is 0.65650826446281\n",
      "Recall is 0.505568814638027\n",
      "... Processing cond-mat\n",
      "Instances: 17576\n",
      "Test accuracy is 0.9502912401741785\n",
      "Precision is 0.8487938931297709\n",
      "Recall is 0.7907942649066909\n",
      "... Processing math-ph\n",
      "Instances: 3765\n",
      "Test accuracy is 0.970229679837778\n",
      "Precision is 0.6234567901234568\n",
      "Recall is 0.053652058432934926\n",
      "... Processing nucl-ex\n",
      "Instances: 1216\n",
      "Test accuracy is 0.991783876362285\n",
      "Precision is 0.6335570469798658\n",
      "Recall is 0.3881578947368421\n",
      "... Processing hep-lat\n",
      "Instances: 1044\n",
      "Test accuracy is 0.9949749961625775\n",
      "Precision is 0.8370607028753994\n",
      "Recall is 0.5019157088122606\n",
      "... Processing hep-ph\n",
      "Instances: 6539\n",
      "Test accuracy is 0.9754889684200322\n",
      "Precision is 0.8136746017540719\n",
      "Recall is 0.6952133353723811\n",
      "... Processing quant-ph\n",
      "Instances: 7020\n",
      "Test accuracy is 0.9698661345440738\n",
      "Precision is 0.816711590296496\n",
      "Recall is 0.6042735042735042\n",
      "... Processing nucl-th\n",
      "Instances: 2301\n",
      "Test accuracy is 0.9872839935046575\n",
      "Precision is 0.7361923326835608\n",
      "Recall is 0.4923946110386788\n",
      "... Processing stat\n",
      "Instances: 7538\n",
      "Test accuracy is 0.95944450279122\n",
      "Precision is 0.7744115082824761\n",
      "Recall is 0.4713451843990448\n",
      "... Processing econ\n",
      "Instances: 109\n",
      "Test accuracy is 0.9991194125108054\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing hep-th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 6209\n",
      "Test accuracy is 0.969704558857983\n",
      "Precision is 0.7792414263002498\n",
      "Recall is 0.5525849573200193\n",
      "... Processing nlin\n",
      "Instances: 1834\n",
      "Test accuracy is 0.9867427149562534\n",
      "Precision is 0.7480719794344473\n",
      "Recall is 0.15866957470010906\n",
      "... Processing gr-qc\n",
      "Instances: 4589\n",
      "Test accuracy is 0.9794394939449511\n",
      "Precision is 0.7923340961098398\n",
      "Recall is 0.6036173458269776\n",
      "... Processing astro-ph\n",
      "Instances: 15127\n",
      "Test accuracy is 0.9755697562630775\n",
      "Precision is 0.9306810903138567\n",
      "Recall is 0.8644807298208501\n",
      "... Processing math\n",
      "Instances: 38456\n",
      "Test accuracy is 0.9168531519376965\n",
      "Precision is 0.8738650241597197\n",
      "Recall is 0.8559132515082172\n"
     ]
    }
   ],
   "source": [
    "SVC_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(max_features = 2000)),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "svc_predictions = []\n",
    "for i in range(len(categories)):\n",
    "    print('... Processing {}'.format(mlb.classes_[i]))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(train_X, bin_train_Y[:,i])\n",
    "    \n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(test_X)\n",
    "    svc_predictions.append(prediction)\n",
    "    \n",
    "    print('Instances: {}'.format(np.sum(bin_test_Y[:,i])))\n",
    "    print('Test accuracy is {}'.format(accuracy_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Precision is {}'.format(precision_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Recall is {}'.format(recall_score(bin_test_Y[:,i], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing gr-qc\n",
      "Instances: 4589\n",
      "Test accuracy is 0.9718050427771628\n",
      "Precision is 0.6222469410456062\n",
      "Recall is 0.6095009806057965\n",
      "... Processing stat\n",
      "Instances: 7538\n",
      "Test accuracy is 0.9469304659034908\n",
      "Precision is 0.5698026221005619\n",
      "Recall is 0.5246749801008225\n",
      "... Processing math\n",
      "Instances: 38456\n",
      "Test accuracy is 0.91023662759228\n",
      "Precision is 0.8570309439874657\n",
      "Recall is 0.8534428957769918\n",
      "... Processing math-ph\n",
      "Instances: 3765\n",
      "Test accuracy is 0.9587658849096388\n",
      "Precision is 0.2940633651184251\n",
      "Recall is 0.2539176626826029\n",
      "... Processing q-fin\n",
      "Instances: 895\n",
      "Test accuracy is 0.9936258391837196\n",
      "Precision is 0.5619158878504673\n",
      "Recall is 0.5374301675977654\n",
      "... Processing nlin\n",
      "Instances: 1834\n",
      "Test accuracy is 0.9802716087283185\n",
      "Precision is 0.3401682439537329\n",
      "Recall is 0.35278080697928027\n",
      "... Processing eess\n",
      "Instances: 698\n",
      "Test accuracy is 0.9943367722025189\n",
      "Precision is 0.2\n",
      "Recall is 0.0014326647564469914\n",
      "... Processing hep-lat\n",
      "Instances: 1044\n",
      "Test accuracy is 0.9918404278524168\n",
      "Precision is 0.5148342059336823\n",
      "Recall is 0.5651340996168582\n",
      "... Processing econ\n",
      "Instances: 109\n",
      "Test accuracy is 0.9989820731776282\n",
      "Precision is 0.09523809523809523\n",
      "Recall is 0.01834862385321101\n",
      "... Processing nucl-ex\n",
      "Instances: 1216\n",
      "Test accuracy is 0.9882049749153747\n",
      "Precision is 0.4090909090909091\n",
      "Recall is 0.45148026315789475\n",
      "... Processing astro-ph\n",
      "Instances: 15127\n",
      "Test accuracy is 0.9679029899580711\n",
      "Precision is 0.8688492063492064\n",
      "Recall is 0.8684471474846301\n",
      "... Processing cond-mat\n",
      "Instances: 17576\n",
      "Test accuracy is 0.942260928575468\n",
      "Precision is 0.8033273224361585\n",
      "Recall is 0.7857305416477014\n",
      "... Processing hep-ph\n",
      "Instances: 6539\n",
      "Test accuracy is 0.9688886016432248\n",
      "Precision is 0.7079207920792079\n",
      "Recall is 0.6998011928429424\n",
      "... Processing quant-ph\n",
      "Instances: 7020\n",
      "Test accuracy is 0.960632084083987\n",
      "Precision is 0.6586375055415989\n",
      "Recall is 0.6349002849002849\n",
      "... Processing cs\n",
      "Instances: 30686\n",
      "Test accuracy is 0.9267173475735372\n",
      "Precision is 0.8651305787357682\n",
      "Recall is 0.8344847813335071\n",
      "... Processing q-bio\n",
      "Instances: 2482\n",
      "Test accuracy is 0.9801019542579232\n",
      "Precision is 0.5037954454654414\n",
      "Recall is 0.508058017727639\n",
      "... Processing physics\n",
      "Instances: 14548\n",
      "Test accuracy is 0.9089601796721629\n",
      "Precision is 0.6387173195701836\n",
      "Recall is 0.5189029419851526\n",
      "... Processing hep-th\n",
      "Instances: 6209\n",
      "Test accuracy is 0.9627002528659487\n",
      "Precision is 0.6356509884117246\n",
      "Recall is 0.6007408600418747\n",
      "... Processing nucl-th\n",
      "Instances: 2301\n",
      "Test accuracy is 0.9818792868049216\n",
      "Precision is 0.5121848739495798\n",
      "Recall is 0.5297696653628857\n",
      "... Processing hep-ex\n",
      "Instances: 2514\n",
      "Test accuracy is 0.978655851867411\n",
      "Precision is 0.477512297962052\n",
      "Recall is 0.5405727923627685\n"
     ]
    }
   ],
   "source": [
    "svc_predictions = []\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    print('... Processing {}'.format(mlb.classes_[i]))\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features = 10000)\n",
    "    tfidf_matrix =  vectorizer.fit_transform(np.array(train_X)[bin_train_Y[:,i] == 1])\n",
    "    \n",
    "    clf = LinearSVC()\n",
    "    clf.fit(vectorizer.transform(train_X), bin_train_Y[:,i])\n",
    "    \n",
    "    # compute the testing accuracy\n",
    "    prediction = clf.predict(vectorizer.transform(test_X))\n",
    "    svc_predictions.append(prediction)\n",
    "    \n",
    "    print('Instances: {}'.format(np.sum(bin_test_Y[:,i])))\n",
    "    print('Test accuracy is {}'.format(accuracy_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Precision is {}'.format(precision_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Recall is {}'.format(recall_score(bin_test_Y[:,i], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing cs\n",
      "Instances: 30686\n",
      "Test accuracy is 0.9334388961149126\n",
      "Precision is 0.8860454717435421\n",
      "Recall is 0.8394707684285994\n",
      "... Processing eess\n",
      "Instances: 698\n",
      "Test accuracy is 0.9943610085554325\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing physics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 14548\n",
      "Test accuracy is 0.9124663720603323\n",
      "Precision is 0.7234862164439629\n",
      "Recall is 0.41311520483915315\n",
      "... Processing q-bio\n",
      "Instances: 2482\n",
      "Test accuracy is 0.9841817403317149\n",
      "Precision is 0.7258620689655172\n",
      "Recall is 0.33924254633360196\n",
      "... Processing q-fin\n",
      "Instances: 895\n",
      "Test accuracy is 0.9940944086733828\n",
      "Precision is 0.7546583850931677\n",
      "Recall is 0.27150837988826815\n",
      "... Processing hep-ex\n",
      "Instances: 2514\n",
      "Test accuracy is 0.9845533644097236\n",
      "Precision is 0.6764361078546307\n",
      "Recall is 0.4590294351630867\n",
      "... Processing cond-mat\n",
      "Instances: 17576\n",
      "Test accuracy is 0.9492329194302841\n",
      "Precision is 0.8556311413454271\n",
      "Recall is 0.7728720983158853\n",
      "... Processing math-ph\n",
      "Instances: 3765\n",
      "Test accuracy is 0.9699953950929464\n",
      "Precision is 0.5452930728241563\n",
      "Recall is 0.08154050464807437\n",
      "... Processing nucl-ex\n",
      "Instances: 1216\n",
      "Test accuracy is 0.9915091976959307\n",
      "Precision is 0.6513761467889908\n",
      "Recall is 0.29194078947368424\n",
      "... Processing hep-lat\n",
      "Instances: 1044\n",
      "Test accuracy is 0.9943125358496053\n",
      "Precision is 0.8483606557377049\n",
      "Recall is 0.39655172413793105\n",
      "... Processing hep-ph\n",
      "Instances: 6539\n",
      "Test accuracy is 0.9741478902254789\n",
      "Precision is 0.814584511023177\n",
      "Recall is 0.6611102615078758\n",
      "... Processing quant-ph\n",
      "Instances: 7020\n",
      "Test accuracy is 0.9689855470548792\n",
      "Precision is 0.8230753605525086\n",
      "Recall is 0.5772079772079772\n",
      "... Processing nucl-th\n",
      "Instances: 2301\n",
      "Test accuracy is 0.9864761150742036\n",
      "Precision is 0.7490071485305798\n",
      "Recall is 0.4098218166014776\n",
      "... Processing stat\n",
      "Instances: 7538\n",
      "Test accuracy is 0.9588305151840751\n",
      "Precision is 0.7794050343249428\n",
      "Recall is 0.4518439904483948\n",
      "... Processing econ\n",
      "Instances: 109\n",
      "Test accuracy is 0.9991194125108054\n",
      "Precision is 0.0\n",
      "Recall is 0.0\n",
      "... Processing hep-th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 6209\n",
      "Test accuracy is 0.9689693894862701\n",
      "Precision is 0.7857142857142857\n",
      "Recall is 0.5244000644226123\n",
      "... Processing nlin\n",
      "Instances: 1834\n",
      "Test accuracy is 0.9866861634661216\n",
      "Precision is 0.7657142857142857\n",
      "Recall is 0.14612868047982552\n",
      "... Processing gr-qc\n",
      "Instances: 4589\n",
      "Test accuracy is 0.978566985240061\n",
      "Precision is 0.8044025157232705\n",
      "Recall is 0.5574199171932883\n",
      "... Processing astro-ph\n",
      "Instances: 15127\n",
      "Test accuracy is 0.974269071990047\n",
      "Precision is 0.9361577794010226\n",
      "Recall is 0.8472268129834072\n",
      "... Processing math\n",
      "Instances: 38456\n",
      "Test accuracy is 0.9161906916247243\n",
      "Precision is 0.8774056553058811\n",
      "Recall is 0.848840232993551\n"
     ]
    }
   ],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(max_features = 2000)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "logreg_predictions = []\n",
    "for i in range(len(categories)):\n",
    "    print('... Processing {}'.format(mlb.classes_[i]))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(train_X, bin_train_Y[:,i])\n",
    "    \n",
    "    # compute the testing accuracy\n",
    "    prediction = LogReg_pipeline.predict(test_X)\n",
    "    logreg_predictions.append(prediction)\n",
    "    \n",
    "    print('Instances: {}'.format(np.sum(bin_test_Y[:,i])))\n",
    "    print('Test accuracy is {}'.format(accuracy_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Precision is {}'.format(precision_score(bin_test_Y[:,i], prediction)))\n",
    "    print('Recall is {}'.format(recall_score(bin_test_Y[:,i], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "0.5769140659713526\n",
      "\n",
      "SVM\n",
      "0.5521687496465532\n",
      "\n",
      "Logistic Regression\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logreg_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-970d63ea3fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nLogistic Regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnp_logreg_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_test_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_logreg_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes')\n",
    "np_nb_predictions = np.transpose(np.asarray(nb_predictions))\n",
    "print(accuracy_score(bin_test_Y, np_nb_predictions))\n",
    "\n",
    "print('\\nSVM')\n",
    "np_svc_predictions = np.transpose(np.asarray(svc_predictions))\n",
    "print(accuracy_score(bin_test_Y, np_svc_predictions))\n",
    "\n",
    "print('\\nLogistic Regression')\n",
    "np_logreg_predictions = np.transpose(np.asarray(logreg_predictions))\n",
    "print(accuracy_score(bin_test_Y, np_logreg_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Precision: 0.6544269918738571\n",
      "Recall: 0.8413792029645546\n",
      "\n",
      "SVM\n",
      "Precision: 0.7263996705945043\n",
      "Recall: 0.8542476678772342\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np_logreg_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3ac6c89651df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_predictions\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrue_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_test_Y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp_logreg_predictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mall_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_logreg_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtotal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_test_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np_logreg_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "true_predictions = np.sum(bin_test_Y + np_nb_predictions == 2)\n",
    "all_predictions = np.count_nonzero(np_nb_predictions)\n",
    "total_labels = np.count_nonzero(bin_test_Y)\n",
    "\n",
    "print('Naive Bayes')\n",
    "print('Precision: {}'.format(true_predictions/total_labels))\n",
    "print('Recall: {}'.format(true_predictions/all_predictions))\n",
    "\n",
    "true_predictions = np.sum(bin_test_Y + np_svc_predictions == 2)\n",
    "all_predictions = np.count_nonzero(np_svc_predictions)\n",
    "total_labels = np.count_nonzero(bin_test_Y)\n",
    "\n",
    "print('\\nSVM')\n",
    "print('Precision: {}'.format(true_predictions/total_labels))\n",
    "print('Recall: {}'.format(true_predictions/all_predictions))\n",
    "\n",
    "true_predictions = np.sum(bin_test_Y + np_logreg_predictions == 2)\n",
    "all_predictions = np.count_nonzero(np_logreg_predictions)\n",
    "total_labels = np.count_nonzero(bin_test_Y)\n",
    "\n",
    "print('\\nLogistic Regression')\n",
    "print('Precision: {}'.format(true_predictions/total_labels))\n",
    "print('Recall: {}'.format(true_predictions/all_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, lower=True)\n",
    "tokenizer.fit_on_texts(train_X)\n",
    "sequences = tokenizer.texts_to_sequences(train_X)\n",
    "X_nn = pad_sequences(sequences, maxlen=180)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(test_X)\n",
    "test_X_nn = pad_sequences(sequences, maxlen=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102092 samples, validate on 11344 samples\n",
      "Epoch 1/20\n",
      "102092/102092 [==============================] - 19s 187us/step - loss: 0.1218 - acc: 0.9584 - categorical_accuracy: 0.6108 - val_loss: 0.1025 - val_acc: 0.9643 - val_categorical_accuracy: 0.6683\n",
      "Epoch 2/20\n",
      "102092/102092 [==============================] - 19s 182us/step - loss: 0.1003 - acc: 0.9643 - categorical_accuracy: 0.6703 - val_loss: 0.0989 - val_acc: 0.9653 - val_categorical_accuracy: 0.6729\n",
      "Epoch 3/20\n",
      "102092/102092 [==============================] - 19s 183us/step - loss: 0.0976 - acc: 0.9652 - categorical_accuracy: 0.6794 - val_loss: 0.0970 - val_acc: 0.9653 - val_categorical_accuracy: 0.6792\n",
      "Epoch 4/20\n",
      "102092/102092 [==============================] - 19s 183us/step - loss: 0.0967 - acc: 0.9654 - categorical_accuracy: 0.6804 - val_loss: 0.0968 - val_acc: 0.9654 - val_categorical_accuracy: 0.6811\n",
      "Epoch 5/20\n",
      "102092/102092 [==============================] - 19s 182us/step - loss: 0.0960 - acc: 0.9657 - categorical_accuracy: 0.6825 - val_loss: 0.0960 - val_acc: 0.9655 - val_categorical_accuracy: 0.6767\n",
      "Epoch 6/20\n",
      "102092/102092 [==============================] - 19s 182us/step - loss: 0.0953 - acc: 0.9660 - categorical_accuracy: 0.6856 - val_loss: 0.0956 - val_acc: 0.9659 - val_categorical_accuracy: 0.6866\n",
      "Epoch 7/20\n",
      "102092/102092 [==============================] - 19s 183us/step - loss: 0.0948 - acc: 0.9661 - categorical_accuracy: 0.6868 - val_loss: 0.0964 - val_acc: 0.9657 - val_categorical_accuracy: 0.6891\n",
      "Epoch 8/20\n",
      "102092/102092 [==============================] - 19s 183us/step - loss: 0.0948 - acc: 0.9662 - categorical_accuracy: 0.6870 - val_loss: 0.0952 - val_acc: 0.9658 - val_categorical_accuracy: 0.6737\n",
      "Epoch 9/20\n",
      "102092/102092 [==============================] - 19s 183us/step - loss: 0.0943 - acc: 0.9664 - categorical_accuracy: 0.6890 - val_loss: 0.0953 - val_acc: 0.9656 - val_categorical_accuracy: 0.6841\n",
      "Epoch 10/20\n",
      "102092/102092 [==============================] - 19s 184us/step - loss: 0.0939 - acc: 0.9665 - categorical_accuracy: 0.6900 - val_loss: 0.0946 - val_acc: 0.9662 - val_categorical_accuracy: 0.6855\n",
      "Epoch 11/20\n",
      "102092/102092 [==============================] - 19s 183us/step - loss: 0.0936 - acc: 0.9666 - categorical_accuracy: 0.6914 - val_loss: 0.0951 - val_acc: 0.9659 - val_categorical_accuracy: 0.6836\n",
      "Epoch 12/20\n",
      "102092/102092 [==============================] - 19s 186us/step - loss: 0.0930 - acc: 0.9668 - categorical_accuracy: 0.6920 - val_loss: 0.0941 - val_acc: 0.9665 - val_categorical_accuracy: 0.6858\n",
      "Epoch 13/20\n",
      "102092/102092 [==============================] - 20s 198us/step - loss: 0.0929 - acc: 0.9668 - categorical_accuracy: 0.6909 - val_loss: 0.0935 - val_acc: 0.9663 - val_categorical_accuracy: 0.6886\n",
      "Epoch 14/20\n",
      "102092/102092 [==============================] - 22s 212us/step - loss: 0.0927 - acc: 0.9668 - categorical_accuracy: 0.6926 - val_loss: 0.0944 - val_acc: 0.9665 - val_categorical_accuracy: 0.6811\n",
      "Epoch 15/20\n",
      "102092/102092 [==============================] - 21s 205us/step - loss: 0.0929 - acc: 0.9668 - categorical_accuracy: 0.6923 - val_loss: 0.0948 - val_acc: 0.9661 - val_categorical_accuracy: 0.6835\n",
      "Epoch 16/20\n",
      "102092/102092 [==============================] - 20s 199us/step - loss: 0.0929 - acc: 0.9668 - categorical_accuracy: 0.6916 - val_loss: 0.0940 - val_acc: 0.9664 - val_categorical_accuracy: 0.6788\n",
      "Epoch 17/20\n",
      "102092/102092 [==============================] - 19s 185us/step - loss: 0.0924 - acc: 0.9670 - categorical_accuracy: 0.6945 - val_loss: 0.0935 - val_acc: 0.9661 - val_categorical_accuracy: 0.6780\n",
      "Epoch 18/20\n",
      "102092/102092 [==============================] - 19s 186us/step - loss: 0.0921 - acc: 0.9670 - categorical_accuracy: 0.6938 - val_loss: 0.0928 - val_acc: 0.9667 - val_categorical_accuracy: 0.6967\n",
      "Epoch 19/20\n",
      "102092/102092 [==============================] - 19s 185us/step - loss: 0.0921 - acc: 0.9671 - categorical_accuracy: 0.6956 - val_loss: 0.0948 - val_acc: 0.9659 - val_categorical_accuracy: 0.6869\n",
      "Epoch 20/20\n",
      "102092/102092 [==============================] - 19s 185us/step - loss: 0.0921 - acc: 0.9670 - categorical_accuracy: 0.6955 - val_loss: 0.0941 - val_acc: 0.9663 - val_categorical_accuracy: 0.6830\n",
      "123781/123781 [==============================] - 3s 21us/step\n",
      "loss: 0.09639169582160143\n",
      "acc: 0.9669266766610648\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import models\n",
    "\n",
    "max_words = 10000\n",
    "maxlen = 180\n",
    "num_classes = len(categories)\n",
    "filter_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.15))\n",
    "#model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(0.015), loss='binary_crossentropy', metrics=['accuracy', 'categorical_accuracy'])\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-simple.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(X_nn, bin_train_Y,\n",
    "                    #class_weight=class_weight,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "simple_model = models.load_model('model-simple.h5')\n",
    "metrics = simple_model.evaluate(test_X_nn, bin_test_Y)\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123781/123781 [==============================] - 3s 21us/step\n",
      "loss: 0.09661265691515634\n",
      "acc: 0.966862449445216\n"
     ]
    }
   ],
   "source": [
    "simple_model = models.load_model('model-simple.h5')\n",
    "metrics = simple_model.evaluate(test_X_nn, bin_test_Y)\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_accuracy: 0.6885790226296379\n"
     ]
    }
   ],
   "source": [
    "print(\"{}: {}\".format(simple_model.metrics_names[2], metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_pos = defaultdict(int)\n",
    "terms_neg = defaultdict(int)\n",
    "for i in range(len(train_y)):\n",
    "    if 'eess' in train_y[i]:\n",
    "        for word in train_x[i].split():\n",
    "            terms_pos[word] += 1\n",
    "    else:\n",
    "        for word in train_x[i].split():\n",
    "            terms_neg[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
